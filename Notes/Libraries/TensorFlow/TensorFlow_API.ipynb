{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Contents\">Contents<a href=\"#Contents\"></a></h2>\n",
    "        <ol>\n",
    "        <li><a class=\"\" href=\"#All-Modules\">All Modules</a></li>\n",
    "<li><a class=\"\" href=\"#Important-Modules\">Important Modules</a></li>\n",
    "<ol><li><a class=\"\" href=\"#tf.audio\">tf.audio</a></li>\n",
    "<li><a class=\"\" href=\"#tf.autodiff\">tf.autodiff</a></li>\n",
    "<li><a class=\"\" href=\"#tf.data\">tf.data</a></li>\n",
    "<li><a class=\"\" href=\"#tf.dtypes\">tf.dtypes</a></li>\n",
    "<li><a class=\"\" href=\"#tf.image\">tf.image</a></li>\n",
    "<li><a class=\"\" href=\"#tf.io\">tf.io</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras\">tf.keras</a></li>\n",
    "<ol><li><a class=\"\" href=\"#tf.keras.activations\">tf.keras.activations</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.callbacks\">tf.keras.callbacks</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.datasets\">tf.keras.datasets</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.initializers\">tf.keras.initializers</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.layers\">tf.keras.layers</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.losses\">tf.keras.losses</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.models\">tf.keras.models</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.optimizers\">tf.keras.optimizers</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.regularizers\">tf.keras.regularizers</a></li>\n",
    "<li><a class=\"\" href=\"#tf.keras.utils\">tf.keras.utils</a></li>\n",
    "</ol><li><a class=\"\" href=\"#tf.linalg\">tf.linalg</a></li>\n",
    "<li><a class=\"\" href=\"#tf.losses\">tf.losses</a></li>\n",
    "<li><a class=\"\" href=\"#tf.math\">tf.math</a></li>\n",
    "<li><a class=\"\" href=\"#tf.strings\">tf.strings</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has the followings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio: Public API for tf.audio namespace.\n",
    "\n",
    "autodiff: Public API for tf.autodiff namespace.\n",
    "\n",
    "autograph: Conversion of eager-style Python into TensorFlow graph code.\n",
    "\n",
    "bitwise: Operations for manipulating the binary representations of integers.\n",
    "\n",
    "compat: Compatibility functions.\n",
    "\n",
    "config: Public API for tf.config namespace.\n",
    "\n",
    "data: tf.data.Dataset API for input pipelines.\n",
    "\n",
    "debugging: Public API for tf.debugging namespace.\n",
    "\n",
    "distribute: Library for running a computation across multiple devices.\n",
    "\n",
    "dtypes: Public API for tf.dtypes namespace.\n",
    "\n",
    "errors: Exception types for TensorFlow errors.\n",
    "\n",
    "estimator: Estimator: High level tools for working with models.\n",
    "\n",
    "experimental: Public API for tf.experimental namespace.\n",
    "\n",
    "feature_column: Public API for tf.feature_column namespace.\n",
    "\n",
    "graph_util: Helpers to manipulate a tensor graph in python.\n",
    "\n",
    "image: Image ops.\n",
    "\n",
    "io: Public API for tf.io namespace.\n",
    "\n",
    "keras: Implementation of the Keras API, the high-level API of TensorFlow.\n",
    "\n",
    "linalg: Operations for linear algebra.\n",
    "\n",
    "lite: Public API for tf.lite namespace.\n",
    "\n",
    "lookup: Public API for tf.lookup namespace.\n",
    "\n",
    "math: Math Operations.\n",
    "\n",
    "mlir: Public API for tf.mlir namespace.\n",
    "\n",
    "nest: Functions that work with structures.\n",
    "\n",
    "nn: Primitive Neural Net (NN) Operations.\n",
    "\n",
    "profiler: Public API for tf.profiler namespace.\n",
    "\n",
    "quantization: Public API for tf.quantization namespace.\n",
    "\n",
    "queue: Public API for tf.queue namespace.\n",
    "\n",
    "ragged: Ragged Tensors.\n",
    "\n",
    "random: Public API for tf.random namespace.\n",
    "\n",
    "raw_ops: Public API for tf.raw_ops namespace.\n",
    "\n",
    "saved_model: Public API for tf.saved_model namespace.\n",
    "\n",
    "sets: Tensorflow set operations.\n",
    "\n",
    "signal: Signal processing operations.\n",
    "\n",
    "sparse: Sparse Tensor Representation.\n",
    "\n",
    "strings: Operations for working with string Tensors.\n",
    "\n",
    "summary: Operations for writing summary data, for use in analysis and visualization.\n",
    "\n",
    "sysconfig: System configuration library.\n",
    "\n",
    "test: Testing.\n",
    "\n",
    "tpu: Ops related to Tensor Processing Units.\n",
    "\n",
    "train: Support for training models.\n",
    "\n",
    "types: Public TensorFlow type definitions.\n",
    "\n",
    "version: Public API for tf.version namespace.\n",
    "\n",
    "xla: Public API for tf.xla namespace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss the most important ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.audio`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has two functions:\n",
    "\n",
    "`decode_wav(...)`: Decode a 16-bit PCM WAV file to a float tensor.\n",
    "\n",
    "`encode_wav(...)`: Encode audio data using the WAV file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.autodiff`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class ForwardAccumulator`: Computes Jacobian-vector products (\"JVP\"s) using forward-mode autodiff.\n",
    "\n",
    "`class GradientTape`: Record operations for automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class Dataset`: Represents a potentially large set of elements.\n",
    "\n",
    "`class DatasetSpec`: Type specification for tf.data.Dataset.\n",
    "\n",
    "`class FixedLengthRecordDataset`: A Dataset of fixed-length records from one or more binary files.\n",
    "\n",
    "`class Iterator`: Represents an iterator of a tf.data.Dataset.\n",
    "\n",
    "`class IteratorSpec`: Type specification for tf.data.Iterator.\n",
    "\n",
    "`class Options`: Represents options for tf.data.Dataset.\n",
    "\n",
    "`class TFRecordDataset`: A Dataset comprising records from one or more TFRecord files.\n",
    "\n",
    "`class TextLineDataset`: Creates a Dataset comprising lines from one or more text files.\n",
    "\n",
    "`class ThreadingOptions`: Represents options for dataset threading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.dtypes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_dtype(...)`: Converts the given type_value to a DType.\n",
    "\n",
    "`cast(...)`: Casts a tensor to a new type.\n",
    "\n",
    "`complex(...)`: Converts two real numbers to a complex number.\n",
    "\n",
    "`saturate_cast(...)`: Performs a safe saturating cast of value to dtype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dtypes are:\n",
    "\n",
    "<table class=\"responsive fixed orange\">\n",
    "<colgroup><col width=\"214px\"><col></colgroup>\n",
    "<tbody><tr>\n",
    "<td>\n",
    "bfloat16<a id=\"bfloat16\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>16-bit bfloat (brain floating point).\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "bool<a id=\"bool\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Boolean.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "complex128<a id=\"complex128\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>128-bit complex.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "complex64<a id=\"complex64\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>64-bit complex.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "double<a id=\"double\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>64-bit (double precision) floating-point.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "float16<a id=\"float16\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>16-bit (half precision) floating-point.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "float32<a id=\"float32\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>32-bit (single precision) floating-point.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "float64<a id=\"float64\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>64-bit (double precision) floating-point.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "half<a id=\"half\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>16-bit (half precision) floating-point.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "int16<a id=\"int16\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Signed 16-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "int32<a id=\"int32\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Signed 32-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "int64<a id=\"int64\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Signed 64-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "int8<a id=\"int8\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Signed 8-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "qint16<a id=\"qint16\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Signed quantized 16-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "qint32<a id=\"qint32\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>signed quantized 32-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "qint8<a id=\"qint8\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Signed quantized 8-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "quint16<a id=\"quint16\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Unsigned quantized 16-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "quint8<a id=\"quint8\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Unsigned quantized 8-bit integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "resource<a id=\"resource\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Handle to a mutable, dynamically allocated resource.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "string<a id=\"string\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Variable-length string, represented as byte array.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "uint16<a id=\"uint16\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Unsigned 16-bit (word) integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "uint32<a id=\"uint32\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Unsigned 32-bit (dword) integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "uint64<a id=\"uint64\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Unsigned 64-bit (qword) integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "uint8<a id=\"uint8\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Unsigned 8-bit (byte) integer.\n",
    "</p></td>\n",
    "</tr><tr>\n",
    "<td>\n",
    "variant<a id=\"variant\"></a>\n",
    "</td>\n",
    "<td>\n",
    "Instance of <a href=\"https://www.tensorflow.org/api_docs/python/tf/dtypes/DType\"><code translate=\"no\" dir=\"ltr\">tf.dtypes.DType</code></a><p></p>\n",
    "\n",
    "<p>Data of arbitrary type (known at runtime).\n",
    "</p></td>\n",
    "</tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.image`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.image` module contains various functions for image processing and decoding-encoding Ops. Some examples are:\n",
    "1. Resizing\n",
    "    - `tf.image.resize`\n",
    "    - `tf.image.resize_with_pad`\n",
    "    - `tf.image.resize_with_crop_or_pad`\n",
    "2. Converting Between Colorspaces\n",
    "    - `tf.image.rgb_to_grayscale`\n",
    "    - `tf.image.grayscale_to_rgb`\n",
    "    - `tf.image.rgb_to_yuv`\n",
    "    - `tf.image.yuv_to_rgb`\n",
    "    - `tf.image.rgb_to_yiq`\n",
    "    - `tf.image.yiq_to_rgb`\n",
    "    - `tf.image.rgb_to_hsv`\n",
    "    - `tf.image.hsv_to_rgb`\n",
    "3. Image Transformations\n",
    "    - `tf.image.flip_left_right`\n",
    "    - `tf.image.flip_up_down`\n",
    "    - `tf.image.transpose_image`\n",
    "    - `tf.image.rot90`\n",
    "    - `tf.image.random_flip_left_right`\n",
    "    - `tf.image.random_flip_up_down`\n",
    "    - `tf.image.random_brightness`\n",
    "    - `tf.image.random_contrast`\n",
    "    - `tf.image.random_hue`\n",
    "    - `tf.image.random_jpeg_quality`\n",
    "    - `tf.image.random_saturation`\n",
    "4. Cropping\n",
    "    - `tf.image.central_crop`\n",
    "    - `tf.image.crop_and_resize`\n",
    "    - `tf.image.crop_to_bounding_box`\n",
    "    - `tf.image.extract_glimpse`\n",
    "    - `tf.image.random_crop`\n",
    "5. Working with Bounding Boxes\n",
    "    - `tf.image.draw_bounding_boxes`\n",
    "    - `tf.image.non_max_suppression`\n",
    "    - `tf.image.non_max_suppression_with_scores`\n",
    "    - `tf.image.sample_distorted_bounding_box`\n",
    "    - `tf.image.sample_distorted_bounding_box_v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.io`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some classes are:\n",
    "\n",
    "`class FixedLenFeature`: Configuration for parsing a fixed-length input feature.\n",
    "\n",
    "`class FixedLenSequenceFeature`: Configuration for parsing a variable-length input feature into a Tensor.\n",
    "\n",
    "`class RaggedFeature`: Configuration for passing a RaggedTensor input feature.\n",
    "\n",
    "`class SparseFeature`: Configuration for parsing a sparse input feature from an Example.\n",
    "\n",
    "`class TFRecordOptions`: Options used for manipulating TFRecord files.\n",
    "\n",
    "`class TFRecordWriter`: A class to write records to a TFRecords file.\n",
    "\n",
    "`class VarLenFeature`: Configuration for parsing a variable-length input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions are:\n",
    "\n",
    "decode_and_crop_jpeg(...): Decode and Crop a JPEG-encoded image to a uint8 tensor.\n",
    "\n",
    "decode_base64(...): Decode web-safe base64-encoded strings.\n",
    "\n",
    "decode_bmp(...): Decode the first frame of a BMP-encoded image to a uint8 tensor.\n",
    "\n",
    "decode_compressed(...): Decompress strings.\n",
    "\n",
    "decode_csv(...): Convert CSV records to tensors. Each column maps to one tensor.\n",
    "\n",
    "decode_gif(...): Decode the frame(s) of a GIF-encoded image to a uint8 tensor.\n",
    "\n",
    "decode_image(...): Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.\n",
    "\n",
    "decode_jpeg(...): Decode a JPEG-encoded image to a uint8 tensor.\n",
    "\n",
    "decode_json_example(...): Convert JSON-encoded Example records to binary protocol buffer strings.\n",
    "\n",
    "decode_png(...): Decode a PNG-encoded image to a uint8 or uint16 tensor.\n",
    "\n",
    "decode_proto(...): The op extracts fields from a serialized protocol buffers message into tensors.\n",
    "\n",
    "decode_raw(...): Convert raw bytes from input tensor into numeric tensors.\n",
    "\n",
    "deserialize_many_sparse(...): Deserialize and concatenate SparseTensors from a serialized minibatch.\n",
    "\n",
    "encode_base64(...): Encode strings into web-safe base64 format.\n",
    "\n",
    "encode_jpeg(...): JPEG-encode an image.\n",
    "\n",
    "encode_png(...): PNG-encode an image.\n",
    "\n",
    "encode_proto(...): The op serializes protobuf messages provided in the input tensors.\n",
    "\n",
    "extract_jpeg_shape(...): Extract the shape information of a JPEG-encoded image.\n",
    "\n",
    "is_jpeg(...): Convenience function to check if the 'contents' encodes a JPEG image.\n",
    "\n",
    "match_filenames_once(...): Save the list of files matching pattern, so it is only computed once.\n",
    "\n",
    "matching_files(...): Returns the set of files matching one or more glob patterns.\n",
    "\n",
    "parse_example(...): Parses Example protos into a dict of tensors.\n",
    "\n",
    "parse_sequence_example(...): Parses a batch of SequenceExample protos.\n",
    "\n",
    "parse_single_example(...): Parses a single Example proto.\n",
    "\n",
    "parse_single_sequence_example(...): Parses a single SequenceExample proto.\n",
    "\n",
    "parse_tensor(...): Transforms a serialized tensorflow.TensorProto proto into a Tensor.\n",
    "\n",
    "read_file(...): Reads the contents of file.\n",
    "\n",
    "serialize_many_sparse(...): Serialize N-minibatch SparseTensor into an [N, 3] Tensor.\n",
    "\n",
    "serialize_sparse(...): Serialize a SparseTensor into a 3-vector (1-D Tensor) object.\n",
    "\n",
    "serialize_tensor(...): Transforms a Tensor into a serialized TensorProto proto.\n",
    "\n",
    "write_file(...): Writes contents to the file at input filename.\n",
    "\n",
    "write_graph(...): Writes a graph proto to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the Keras API, the high-level API of TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module has huge numbers of sub-modules. Some of t`:\n",
    "\n",
    "`activations`: Built-in activation functions.\n",
    "\n",
    "`callbacks`: Built-in callbacks.\n",
    "\n",
    "`datasets`: Small NumPy datasets for debugging/testing.\n",
    "\n",
    "`initializers`: Keras initializer serialization / deserialization.\n",
    "\n",
    "`layers`: Keras layers API.\n",
    "\n",
    "`losses`: Built-in loss functions.\n",
    "\n",
    "`metrics`: All Keras metrics.\n",
    "\n",
    "`models`: Keras models API.\n",
    "\n",
    "`optimizers`: Built-in optimizer classes.\n",
    "\n",
    "`preprocessing`: Utilities to preprocess data before training.\n",
    "\n",
    "`regularizers`: Built-in regularizers.\n",
    "\n",
    "`utils`: Public Keras utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes in the main module are:\n",
    "\n",
    "`class Model`: Model groups layers into an object with training and inference features.\n",
    "\n",
    "`class Sequential`: Sequential groups a linear stack of layers into a `tf.keras.Model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.activations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deserialize(...): Returns activation function given a string identifier.\n",
    "\n",
    "elu(...): Exponential Linear Unit.\n",
    "\n",
    "exponential(...): Exponential activation function.\n",
    "\n",
    "gelu(...): Applies the Gaussian error linear unit (GELU) activation function.\n",
    "\n",
    "get(...): Returns function.\n",
    "\n",
    "hard_sigmoid(...): Hard sigmoid activation function.\n",
    "\n",
    "linear(...): Linear activation function (pass-through).\n",
    "\n",
    "relu(...): Applies the rectified linear unit activation function.\n",
    "\n",
    "selu(...): Scaled Exponential Linear Unit (SELU).\n",
    "\n",
    "serialize(...): Returns the string identifier of an activation function.\n",
    "\n",
    "sigmoid(...): Sigmoid activation function, sigmoid(x) = 1 / (1 + exp(-x)).\n",
    "\n",
    "softmax(...): Softmax converts a vector of values to a probability distribution.\n",
    "\n",
    "softplus(...): Softplus activation function, softplus(x) = log(exp(x) + 1).\n",
    "\n",
    "softsign(...): Softsign activation function, softsign(x) = x / (abs(x) + 1).\n",
    "\n",
    "swish(...): Swish activation function, swish(x) = x * sigmoid(x).\n",
    "\n",
    "tanh(...): Hyperbolic tangent activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.callbacks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks: utilities called at certain points during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class BackupAndRestore`:` Callback to back up and restore the training state.\n",
    "\n",
    "`class BaseLogger`:` Callback that accumulates epoch averages of metrics.\n",
    "\n",
    "`class CSVLogger`:` Callback that streams epoch results to a CSV file.\n",
    "\n",
    "`class Callback`:` Abstract base class used to build new callbacks.\n",
    "\n",
    "`class CallbackList`:` Container abstracting a list of callbacks.\n",
    "\n",
    "`class EarlyStopping`:` Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "`class History`:` Callback that records events into a History object.\n",
    "\n",
    "`class LambdaCallback`:` Callback for creating simple, custom callbacks on-the-fly.\n",
    "\n",
    "`class LearningRateScheduler`:` Learning rate scheduler.\n",
    "\n",
    "`class ModelCheckpoint`:` Callback to save the Keras model or model weights at some frequency.\n",
    "\n",
    "`class ProgbarLogger`:` Callback that prints metrics to stdout.\n",
    "\n",
    "`class ReduceLROnPlateau`:` Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "`class RemoteMonitor`:` Callback used to stream events to a server.\n",
    "\n",
    "`class TensorBoard`:` Enable visualizations for TensorBoard.\n",
    "\n",
    "`class TerminateOnNaN`:` Callback that terminates training when a NaN loss is encountered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`boston_housing`: Boston housing price regression dataset.\n",
    "\n",
    "`cifar10`: CIFAR10 small images classification dataset.\n",
    "\n",
    "`cifar100`: CIFAR100 small images classification dataset.\n",
    "\n",
    "`fashion_mnist`: Fashion-MNIST dataset.\n",
    "\n",
    "`imdb`: IMDB sentiment classification dataset.\n",
    "\n",
    "`mnist`: MNIST handwritten digits dataset.\n",
    "\n",
    "`reuters`: Reuters topic classification dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.initializers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras initializer serialization / deserialization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class Constant`: Initializer that generates tensors with constant values.\n",
    "\n",
    "`class GlorotNormal`: The Glorot normal initializer, also called Xavier normal initializer.\n",
    "\n",
    "`class GlorotUniform`: The Glorot uniform initializer, also called Xavier uniform initializer.\n",
    "\n",
    "`class HeNormal`: He normal initializer.\n",
    "\n",
    "`class HeUniform`: He uniform variance scaling initializer.\n",
    "\n",
    "`class Identity`: Initializer that generates the identity matrix.\n",
    "\n",
    "`class Initializer`: Initializer base class: all Keras initializers inherit from this `class.\n",
    "\n",
    "`class LecunNormal`: Lecun normal initializer.\n",
    "\n",
    "`class LecunUniform`: Lecun uniform initializer.\n",
    "\n",
    "`class Ones`: Initializer that generates tensors initialized to 1.\n",
    "\n",
    "`class Orthogonal`: Initializer that generates an orthogonal matrix.\n",
    "\n",
    "`class RandomNormal`: Initializer that generates tensors with a normal distribution.\n",
    "\n",
    "`class RandomUniform`: Initializer that generates tensors with a uniform distribution.\n",
    "\n",
    "`class TruncatedNormal`: Initializer that generates a truncated normal distribution.\n",
    "\n",
    "`class VarianceScaling`: Initializer capable of adapting its scale to the shape of weights tensors.\n",
    "\n",
    "`class Zeros`: Initializer that generates tensors initialized to 0.\n",
    "\n",
    "`class constant`: Initializer that generates tensors with constant values.\n",
    "\n",
    "`class glorot_normal`: The Glorot normal initializer, also called Xavier normal initializer.\n",
    "\n",
    "`class glorot_uniform`: The Glorot uniform initializer, also called Xavier uniform initializer.\n",
    "\n",
    "`class he_normal`: He normal initializer.\n",
    "\n",
    "`class he_uniform`: He uniform variance scaling initializer.\n",
    "\n",
    "`class identity`: Initializer that generates the identity matrix.\n",
    "\n",
    "`class lecun_normal`: Lecun normal initializer.\n",
    "\n",
    "`class lecun_uniform`: Lecun uniform initializer.\n",
    "\n",
    "`class ones`: Initializer that generates tensors initialized to 1.\n",
    "\n",
    "`class orthogonal`: Initializer that generates an orthogonal matrix.\n",
    "\n",
    "`class random_normal`: Initializer that generates tensors with a normal distribution.\n",
    "\n",
    "`class random_uniform`: Initializer that generates tensors with a uniform distribution.\n",
    "\n",
    "`class truncated_normal`: Initializer that generates a truncated normal distribution.\n",
    "\n",
    "`class variance_scaling`: Initializer capable of adapting its scale to the shape of weights tensors.\n",
    "\n",
    "`class zeros`: Initializer that generates tensors initialized to 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras layers API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are:\n",
    "\n",
    "`class AbstractRNNCell`: Abstract object representing an RNN cell.\n",
    "\n",
    "`class Activation`: Applies an activation function to an output.\n",
    "\n",
    "`class ActivityRegularization`: Layer that applies an update to the cost function based input activity.\n",
    "\n",
    "`class Add`: Layer that adds a list of inputs.\n",
    "\n",
    "`class AdditiveAttention`: Additive attention layer, a.k.a. Bahdanau-style attention.\n",
    "\n",
    "`class AlphaDropout`: Applies Alpha Dropout to the input.\n",
    "\n",
    "`class Attention`: Dot-product attention layer, a.k.a. Luong-style attention.\n",
    "\n",
    "`class Average`: Layer that averages a list of inputs element-wise.\n",
    "\n",
    "`class AveragePooling1D`: Average pooling for temporal data.\n",
    "\n",
    "`class AveragePooling2D`: Average pooling operation for spatial data.\n",
    "\n",
    "`class AveragePooling3D`: Average pooling operation for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "`class AvgPool1D`: Average pooling for temporal data.\n",
    "\n",
    "`class AvgPool2D`: Average pooling operation for spatial data.\n",
    "\n",
    "`class AvgPool3D`: Average pooling operation for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "`class BatchNormalization`: Layer that normalizes its inputs.\n",
    "\n",
    "`class Bidirectional`: Bidirectional wrapper for RNNs.\n",
    "\n",
    "`class CategoryEncoding`: A preprocessing layer which encodes integer features.\n",
    "\n",
    "`class CenterCrop`: A preprocessing layer which crops images.\n",
    "\n",
    "`class Concatenate`: Layer that concatenates a list of inputs.\n",
    "\n",
    "`class Conv1D`: 1D convolution layer (e.g. temporal convolution).\n",
    "\n",
    "`class Conv1DTranspose`: Transposed convolution layer (sometimes called Deconvolution).\n",
    "\n",
    "`class Conv2D`: 2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "`class Conv2DTranspose`: Transposed convolution layer (sometimes called Deconvolution).\n",
    "\n",
    "`class Conv3D`: 3D convolution layer (e.g. spatial convolution over volumes).\n",
    "\n",
    "`class Conv3DTranspose`: Transposed convolution layer (sometimes called Deconvolution).\n",
    "\n",
    "`class ConvLSTM1D`: 1D Convolutional LSTM.\n",
    "\n",
    "`class ConvLSTM2D`: 2D Convolutional LSTM.\n",
    "\n",
    "`class ConvLSTM3D`: 3D Convolutional LSTM.\n",
    "\n",
    "`class Convolution1D`: 1D convolution layer (e.g. temporal convolution).\n",
    "\n",
    "`class Convolution1DTranspose`: Transposed convolution layer (sometimes called Deconvolution).\n",
    "\n",
    "`class Convolution2D`: 2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "`class Convolution2DTranspose`: Transposed convolution layer (sometimes called Deconvolution).\n",
    "\n",
    "`class Convolution3D`: 3D convolution layer (e.g. spatial convolution over volumes).\n",
    "\n",
    "`class Convolution3DTranspose`: Transposed convolution layer (sometimes called Deconvolution).\n",
    "\n",
    "`class Cropping1D`: Cropping layer for 1D input (e.g. temporal sequence).\n",
    "\n",
    "`class Cropping2D`: Cropping layer for 2D input (e.g. picture).\n",
    "\n",
    "`class Cropping3D`: Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n",
    "\n",
    "`class Dense`: Just your regular densely-connected NN layer.\n",
    "\n",
    "`class DenseFeatures`: A layer that produces a dense Tensor based on given feature_columns.\n",
    "\n",
    "`class DepthwiseConv1D`: Depthwise 1D convolution.\n",
    "\n",
    "`class DepthwiseConv2D`: Depthwise 2D convolution.\n",
    "\n",
    "`class Discretization`: A preprocessing layer which buckets continuous features by ranges.\n",
    "\n",
    "`class Dot`: Layer that computes a dot product between samples in two tensors.\n",
    "\n",
    "`class Dropout`: Applies Dropout to the input.\n",
    "\n",
    "`class ELU`: Exponential Linear Unit.\n",
    "\n",
    "`class EinsumDense`: A layer that uses tf.einsum as the backing computation.\n",
    "\n",
    "`class Embedding`: Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "\n",
    "`class Flatten`: Flattens the input. Does not affect the batch size.\n",
    "\n",
    "`class GRU`: Gated Recurrent Unit - Cho et al. 2014.\n",
    "\n",
    "`class GRUCell`: Cell class for the GRU layer.\n",
    "\n",
    "`class GaussianDropout`: Apply multiplicative 1-centered Gaussian noise.\n",
    "\n",
    "`class GaussianNoise`: Apply additive zero-centered Gaussian noise.\n",
    "\n",
    "`class GlobalAveragePooling1D`: Global average pooling operation for temporal data.\n",
    "\n",
    "`class GlobalAveragePooling2D`: Global average pooling operation for spatial data.\n",
    "\n",
    "`class GlobalAveragePooling3D`: Global Average pooling operation for 3D data.\n",
    "\n",
    "`class GlobalAvgPool1D`: Global average pooling operation for temporal data.\n",
    "\n",
    "`class GlobalAvgPool2D`: Global average pooling operation for spatial data.\n",
    "\n",
    "`class GlobalAvgPool3D`: Global Average pooling operation for 3D data.\n",
    "\n",
    "`class GlobalMaxPool1D`: Global max pooling operation for 1D temporal data.\n",
    "\n",
    "`class GlobalMaxPool2D`: Global max pooling operation for spatial data.\n",
    "\n",
    "`class GlobalMaxPool3D`: Global Max pooling operation for 3D data.\n",
    "\n",
    "`class GlobalMaxPooling1D`: Global max pooling operation for 1D temporal data.\n",
    "\n",
    "`class GlobalMaxPooling2D`: Global max pooling operation for spatial data.\n",
    "\n",
    "`class GlobalMaxPooling3D`: Global Max pooling operation for 3D data.\n",
    "\n",
    "`class Hashing`: A preprocessing layer which hashes and bins categorical features.\n",
    "\n",
    "`class InputLayer`: Layer to be used as an entry point into a Network (a graph of layers).\n",
    "\n",
    "`class InputSpec`: Specifies the rank, dtype and shape of every input to a layer.\n",
    "\n",
    "`class IntegerLookup`: A preprocessing layer which maps integer features to contiguous ranges.\n",
    "\n",
    "`class LSTM`: Long Short-Term Memory layer - Hochreiter 1997.\n",
    "\n",
    "`class LSTMCell`: Cell `class for the LSTM layer.\n",
    "\n",
    "`class Lambda`: Wraps arbitrary expressions as a Layer object.\n",
    "\n",
    "`class Layer`: This is the `class from which all layers inherit.\n",
    "\n",
    "`class LayerNormalization`: Layer normalization layer (Ba et al., 2016).\n",
    "\n",
    "`class LeakyReLU`: Leaky version of a Rectified Linear Unit.\n",
    "\n",
    "`class LocallyConnected1D`: Locally-connected layer for 1D inputs.\n",
    "\n",
    "`class LocallyConnected2D`: Locally-connected layer for 2D inputs.\n",
    "\n",
    "`class Masking`: Masks a sequence by using a mask value to skip timesteps.\n",
    "\n",
    "`class MaxPool1D`: Max pooling operation for 1D temporal data.\n",
    "\n",
    "`class MaxPool2D`: Max pooling operation for 2D spatial data.\n",
    "\n",
    "`class MaxPool3D`: Max pooling operation for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "`class MaxPooling1D`: Max pooling operation for 1D temporal data.\n",
    "\n",
    "`class MaxPooling2D`: Max pooling operation for 2D spatial data.\n",
    "\n",
    "`class MaxPooling3D`: Max pooling operation for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "`class Maximum`: Layer that computes the maximum (element-wise) a list of inputs.\n",
    "\n",
    "`class Minimum`: Layer that computes the minimum (element-wise) a list of inputs.\n",
    "\n",
    "`class MultiHeadAttention`: MultiHeadAttention layer.\n",
    "\n",
    "`class Multiply`: Layer that multiplies (element-wise) a list of inputs.\n",
    "\n",
    "`class Normalization`: A preprocessing layer which normalizes continuous features.\n",
    "\n",
    "`class PReLU`: Parametric Rectified Linear Unit.\n",
    "\n",
    "`class Permute`: Permutes the dimensions of the input according to a given pattern.\n",
    "\n",
    "`class RNN`: Base `class for recurrent layers.\n",
    "\n",
    "`class RandomBrightness`: A preprocessing layer which randomly adjusts brightness during training.\n",
    "\n",
    "`class RandomContrast`: A preprocessing layer which randomly adjusts contrast during training.\n",
    "\n",
    "`class RandomCrop`: A preprocessing layer which randomly crops images during training.\n",
    "\n",
    "`class RandomFlip`: A preprocessing layer which randomly flips images during training.\n",
    "\n",
    "`class RandomHeight`: A preprocessing layer which randomly varies image height during training.\n",
    "\n",
    "`class RandomRotation`: A preprocessing layer which randomly rotates images during training.\n",
    "\n",
    "`class RandomTranslation`: A preprocessing layer which randomly translates images during training.\n",
    "\n",
    "`class RandomWidth`: A preprocessing layer which randomly varies image width during training.\n",
    "\n",
    "`class RandomZoom`: A preprocessing layer which randomly zooms images during training.\n",
    "\n",
    "`class ReLU`: Rectified Linear Unit activation function.\n",
    "\n",
    "`class RepeatVector`: Repeats the input n times.\n",
    "\n",
    "`class Rescaling`: A preprocessing layer which rescales input values to a new range.\n",
    "\n",
    "`class Reshape`: Layer that reshapes inputs into the given shape.\n",
    "\n",
    "`class Resizing`: A preprocessing layer which resizes images.\n",
    "\n",
    "`class SeparableConv1D`: Depthwise separable 1D convolution.\n",
    "\n",
    "`class SeparableConv2D`: Depthwise separable 2D convolution.\n",
    "\n",
    "`class SeparableConvolution1D`: Depthwise separable 1D convolution.\n",
    "\n",
    "`class SeparableConvolution2D`: Depthwise separable 2D convolution.\n",
    "\n",
    "`class SimpleRNN`: Fully-connected RNN where the output is to be fed back to input.\n",
    "\n",
    "`class SimpleRNNCell`: Cell `class for SimpleRNN.\n",
    "\n",
    "`class Softmax`: Softmax activation function.\n",
    "\n",
    "`class SpatialDropout1D`: Spatial 1D version of Dropout.\n",
    "\n",
    "`class SpatialDropout2D`: Spatial 2D version of Dropout.\n",
    "\n",
    "`class SpatialDropout3D`: Spatial 3D version of Dropout.\n",
    "\n",
    "`class StackedRNNCells`: Wrapper allowing a stack of RNN cells to behave as a single cell.\n",
    "\n",
    "`class StringLookup`: A preprocessing layer which maps string features to integer indices.\n",
    "\n",
    "`class Subtract`: Layer that subtracts two inputs.\n",
    "\n",
    "`class TextVectorization`: A preprocessing layer which maps text features to integer sequences.\n",
    "\n",
    "`class ThresholdedReLU`: Thresholded Rectified Linear Unit.\n",
    "\n",
    "`class TimeDistributed`: This wrapper allows to apply a layer to every temporal slice of an input.\n",
    "\n",
    "`class UnitNormalization`: Unit normalization layer.\n",
    "\n",
    "`class UpSampling1D`: Upsampling layer for 1D inputs.\n",
    "\n",
    "`class UpSampling2D`: Upsampling layer for 2D inputs.\n",
    "\n",
    "`class UpSampling3D`: Upsampling layer for 3D inputs.\n",
    "\n",
    "`class Wrapper`: Abstract wrapper base class.\n",
    "\n",
    "`class ZeroPadding1D`: Zero-padding layer for 1D input (e.g. temporal sequence).\n",
    "\n",
    "`class ZeroPadding2D`: Zero-padding layer for 2D input (e.g. picture).\n",
    "\n",
    "`class ZeroPadding3D`: Zero-padding layer for 3D data (spatial or spatio-temporal).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from these, we have some functions:\n",
    "\n",
    "Input(...): `Input()` is used to instantiate a Keras tensor.\n",
    "\n",
    "add(...): Functional interface to the tf.keras.layers.`Add` layer.\n",
    "\n",
    "average(...): Functional interface to the tf.keras.layers.`Average` layer.\n",
    "\n",
    "concatenate(...): Functional interface to the `Concatenate` layer.\n",
    "\n",
    "deserialize(...): Instantiates a layer from a config dictionary.\n",
    "\n",
    "dot(...): Functional interface to the `Dot` layer.\n",
    "\n",
    "maximum(...): Functional interface to compute maximum (element-wise) list of inputs.\n",
    "\n",
    "minimum(...): Functional interface to the `Minimum` layer.\n",
    "\n",
    "multiply(...): Functional interface to the `Multiply` layer.\n",
    "\n",
    "serialize(...): Serializes a Layer object into a JSON-compatible representation.\n",
    "\n",
    "subtract(...): Functional interface to the `Subtract` layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.losses`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in loss functions. Classes are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class BinaryCrossentropy`: Computes the cross-entropy loss between true labels and predicted labels.\n",
    "\n",
    "`class BinaryFocalCrossentropy`: Computes the focal cross-entropy loss between true labels and predictions.\n",
    "\n",
    "`class CategoricalCrossentropy`: Computes the crossentropy loss between the labels and predictions.\n",
    "\n",
    "`class CategoricalHinge`: Computes the categorical hinge loss between y_true and y_pred.\n",
    "\n",
    "`class CosineSimilarity`: Computes the cosine similarity between labels and predictions.\n",
    "\n",
    "`class Hinge`: Computes the hinge loss between y_true and y_pred.\n",
    "\n",
    "`class Huber`: Computes the Huber loss between y_true and y_pred.\n",
    "\n",
    "`class KLDivergence`: Computes Kullback-Leibler divergence loss between y_true and y_pred.\n",
    "\n",
    "`class LogCosh`: Computes the logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "`class Loss`: Loss base class.\n",
    "\n",
    "`class MeanAbsoluteError`: Computes the mean of absolute difference between labels and predictions.\n",
    "\n",
    "`class MeanAbsolutePercentageError`: Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "`class MeanSquaredError`: Computes the mean of squares of errors between labels and predictions.\n",
    "\n",
    "`class MeanSquaredLogarithmicError`: Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "`class Poisson`: Computes the Poisson loss between y_true and y_pred.\n",
    "\n",
    "`class Reduction`: Types of loss reduction.\n",
    "\n",
    "`class SparseCategoricalCrossentropy`: Computes the crossentropy loss between the labels and predictions.\n",
    "\n",
    "`class SquaredHinge`: Computes the squared hinge loss between y_true and y_pred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions available are:\n",
    "\n",
    "KLD(...): Computes Kullback-Leibler divergence loss between y_true and y_pred.\n",
    "\n",
    "MAE(...): Computes the mean absolute error between labels and predictions.\n",
    "\n",
    "MAPE(...): Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "MSE(...): Computes the mean squared error between labels and predictions.\n",
    "\n",
    "MSLE(...): Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "binary_crossentropy(...): Computes the binary crossentropy loss.\n",
    "\n",
    "binary_focal_crossentropy(...): Computes the binary focal crossentropy loss.\n",
    "\n",
    "categorical_crossentropy(...): Computes the categorical crossentropy loss.\n",
    "\n",
    "categorical_hinge(...): Computes the categorical hinge loss between y_true and y_pred.\n",
    "\n",
    "cosine_similarity(...): Computes the cosine similarity between labels and predictions.\n",
    "\n",
    "deserialize(...): Deserializes a serialized loss class/function instance.\n",
    "\n",
    "get(...): Retrieves a Keras loss as a function/Loss class instance.\n",
    "\n",
    "hinge(...): Computes the hinge loss between y_true and y_pred.\n",
    "\n",
    "huber(...): Computes Huber loss value.\n",
    "\n",
    "kl_divergence(...): Computes Kullback-Leibler divergence loss between y_true and y_pred.\n",
    "\n",
    "kld(...): Computes Kullback-Leibler divergence loss between y_true and y_pred.\n",
    "\n",
    "kullback_leibler_divergence(...): Computes Kullback-Leibler divergence loss between y_true and y_pred.\n",
    "\n",
    "log_cosh(...): Logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "logcosh(...): Logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "mae(...): Computes the mean absolute error between labels and predictions.\n",
    "\n",
    "mape(...): Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "mean_absolute_error(...): Computes the mean absolute error between labels and predictions.\n",
    "\n",
    "mean_absolute_percentage_error(...): Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "mean_squared_error(...): Computes the mean squared error between labels and predictions.\n",
    "\n",
    "mean_squared_logarithmic_error(...): Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "mse(...): Computes the mean squared error between labels and predictions.\n",
    "\n",
    "msle(...): Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "poisson(...): Computes the Poisson loss between y_true and y_pred.\n",
    "\n",
    "serialize(...): Serializes loss function or Loss instance.\n",
    "\n",
    "sparse_categorical_crossentropy(...): Computes the sparse categorical crossentropy loss.\n",
    "\n",
    "squared_hinge(...): Computes the squared hinge loss between y_true and y_pred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two classes:\n",
    "\n",
    "`class Model`: `Model` groups layers into an object with training and inference features.\n",
    "\n",
    "`class Sequential`: `Sequential` groups a linear stack of layers into a `tf.keras.Model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions are:\n",
    "\n",
    "`clone_model(...)`: Clone a Functional or Sequential Model instance.\n",
    "\n",
    "`load_model(...)`: Loads a model saved via model.save().\n",
    "\n",
    "`model_from_config(...)`: Instantiates a Keras model from its config.\n",
    "\n",
    "`model_from_json(...)`: Parses a JSON model configuration string and returns a model instance.\n",
    "\n",
    "`model_from_yaml(...)`: Parses a yaml model configuration file and returns a model instance.\n",
    "\n",
    "`save_model(...)`: Saves a model as a TensorFlow SavedModel or HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.optimizers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different optimizers are:\n",
    "\n",
    "`class Adadelta`: Optimizer that implements the Adadelta algorithm.\n",
    "\n",
    "`class Adagrad`: Optimizer that implements the Adagrad algorithm.\n",
    "\n",
    "`class Adam`: Optimizer that implements the Adam algorithm.\n",
    "\n",
    "`class Adamax`: Optimizer that implements the Adamax algorithm.\n",
    "\n",
    "`class Ftrl`: Optimizer that implements the FTRL algorithm.\n",
    "\n",
    "`class Nadam`: Optimizer that implements the NAdam algorithm.\n",
    "\n",
    "`class Optimizer`: Base class for Keras optimizers.\n",
    "\n",
    "`class RMSprop`: Optimizer that implements the RMSprop algorithm.\n",
    "\n",
    "`class SGD`: Gradient descent (with momentum) optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.regularizers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in regularizers are:\n",
    "\n",
    "`class L1`: A regularizer that applies a L1 regularization penalty.\n",
    "\n",
    "`class L1L2`: A regularizer that applies both L1 and L2 regularization penalties.\n",
    "\n",
    "`class L2`: A regularizer that applies a L2 regularization penalty.\n",
    "\n",
    "`class OrthogonalRegularizer`: A regularizer that encourages input vectors to be orthogonal to each other.\n",
    "\n",
    "`class Regularizer`: Regularizer base class.\n",
    "\n",
    "`class l1`: A regularizer that applies a L1 regularization penalty.\n",
    "\n",
    "`class l2`: A regularizer that applies a L2 regularization penalty.\n",
    "\n",
    "`class orthogonal_regularizer`: A regularizer that encourages input vectors to be orthogonal to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tf.keras.utils`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some util functions are:\n",
    "\n",
    "array_to_img(...): Converts a 3D Numpy array to a PIL Image instance.\n",
    "\n",
    "audio_dataset_from_directory(...): Generates a tf.data.Dataset from audio files in a directory.\n",
    "\n",
    "deserialize_keras_object(...): Turns the serialized form of a Keras object back into an actual object.\n",
    "\n",
    "disable_interactive_logging(...): Turn off interactive logging.\n",
    "\n",
    "enable_interactive_logging(...): Turn on interactive logging.\n",
    "\n",
    "get_custom_objects(...): Retrieves a live reference to the global dictionary of custom objects.\n",
    "\n",
    "get_file(...): Downloads a file from a URL if it not already in the cache.\n",
    "\n",
    "get_registered_name(...): Returns the name registered to an object within the Keras framework.\n",
    "\n",
    "get_registered_object(...): Returns the class associated with name if it is registered with Keras.\n",
    "\n",
    "get_source_inputs(...): Returns the list of input tensors necessary to compute tensor.\n",
    "\n",
    "image_dataset_from_directory(...): Generates a tf.data.Dataset from image files in a directory.\n",
    "\n",
    "img_to_array(...): Converts a PIL Image instance to a Numpy array.\n",
    "\n",
    "is_interactive_logging_enabled(...): Check if interactive logging is enabled.\n",
    "\n",
    "load_img(...): Loads an image into PIL format.\n",
    "\n",
    "model_to_dot(...): Convert a Keras model to dot format.\n",
    "\n",
    "normalize(...): Normalizes a Numpy array.\n",
    "\n",
    "pack_x_y_sample_weight(...): Packs user-provided data into a tuple.\n",
    "\n",
    "pad_sequences(...): Pads sequences to the same length.\n",
    "\n",
    "plot_model(...): Converts a Keras model to dot format and save to a file.\n",
    "\n",
    "register_keras_serializable(...): Registers an object with the Keras serialization framework.\n",
    "\n",
    "save_img(...): Saves an image stored as a Numpy array to a path or file object.\n",
    "\n",
    "serialize_keras_object(...): Serialize a Keras object into a JSON-compatible representation.\n",
    "\n",
    "set_random_seed(...): Sets all random seeds for the program (Python, NumPy, and TensorFlow).\n",
    "\n",
    "split_dataset(...): Split a dataset into a left half and a right half (e.g. train / test).\n",
    "\n",
    "text_dataset_from_directory(...): Generates a tf.data.Dataset from text files in a directory.\n",
    "\n",
    "timeseries_dataset_from_array(...): Creates a dataset of sliding windows over a timeseries provided as array.\n",
    "\n",
    "to_categorical(...): Converts a class vector (integers) to binary class matrix.\n",
    "\n",
    "unpack_x_y_sample_weight(...): Unpacks user-provided data tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.linalg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations for linear algebra. Some functions are:\n",
    "\n",
    "adjoint(...): Transposes the last two dimensions of and conjugates tensor matrix.\n",
    "\n",
    "band_part(...): Copy a tensor setting everything outside a central band in each innermost matrix to zero.\n",
    "\n",
    "banded_triangular_solve(...): Solve triangular systems of equations with a banded solver.\n",
    "\n",
    "cholesky(...): Computes the Cholesky decomposition of one or more square matrices.\n",
    "\n",
    "cholesky_solve(...): Solves systems of linear eqns A X = RHS, given Cholesky factorizations.\n",
    "\n",
    "cross(...): Compute the pairwise cross product.\n",
    "\n",
    "det(...): Computes the determinant of one or more square matrices.\n",
    "\n",
    "diag(...): Returns a batched diagonal tensor with given batched diagonal values.\n",
    "\n",
    "diag_part(...): Returns the batched diagonal part of a batched tensor.\n",
    "\n",
    "eig(...): Computes the eigen decomposition of a batch of matrices.\n",
    "\n",
    "eigh(...): Computes the eigen decomposition of a batch of self-adjoint matrices.\n",
    "\n",
    "eigh_tridiagonal(...): Computes the eigenvalues of a Hermitian tridiagonal matrix.\n",
    "\n",
    "eigvals(...): Computes the eigenvalues of one or more matrices.\n",
    "\n",
    "eigvalsh(...): Computes the eigenvalues of one or more self-adjoint matrices.\n",
    "\n",
    "einsum(...): Tensor contraction over specified indices and outer product.\n",
    "\n",
    "expm(...): Computes the matrix exponential of one or more square matrices.\n",
    "\n",
    "eye(...): Construct an identity matrix, or a batch of matrices.\n",
    "\n",
    "global_norm(...): Computes the global norm of multiple tensors.\n",
    "\n",
    "inv(...): Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).\n",
    "\n",
    "l2_normalize(...): Normalizes along dimension axis using an L2 norm. (deprecated arguments)\n",
    "\n",
    "logdet(...): Computes log of the determinant of a hermitian positive definite matrix.\n",
    "\n",
    "logm(...): Computes the matrix logarithm of one or more square matrices:\n",
    "\n",
    "lstsq(...): Solves one or more linear least-squares problems.\n",
    "\n",
    "lu(...): Computes the LU decomposition of one or more square matrices.\n",
    "\n",
    "lu_matrix_inverse(...): Computes the inverse given the LU decomposition(s) of one or more matrices.\n",
    "\n",
    "lu_reconstruct(...): The reconstruct one or more matrices from their LU decomposition(s).\n",
    "\n",
    "lu_solve(...): Solves systems of linear eqns A X = RHS, given LU factorizations.\n",
    "\n",
    "matmul(...): Multiplies matrix a by matrix b, producing a * b.\n",
    "\n",
    "matrix_rank(...): Compute the matrix rank of one or more matrices.\n",
    "\n",
    "matrix_transpose(...): Transposes last two dimensions of tensor a.\n",
    "\n",
    "matvec(...): Multiplies matrix a by vector b, producing a * b.\n",
    "\n",
    "norm(...): Computes the norm of vectors, matrices, and tensors.\n",
    "\n",
    "normalize(...): Normalizes tensor along dimension axis using specified norm.\n",
    "\n",
    "pinv(...): Compute the Moore-Penrose pseudo-inverse of one or more matrices.\n",
    "\n",
    "qr(...): Computes the QR decompositions of one or more matrices.\n",
    "\n",
    "set_diag(...): Returns a batched matrix tensor with new batched diagonal values.\n",
    "\n",
    "slogdet(...): Computes the sign and the log of the absolute value of the determinant of\n",
    "\n",
    "solve(...): Solves systems of linear equations.\n",
    "\n",
    "sqrtm(...): Computes the matrix square root of one or more square matrices:\n",
    "\n",
    "svd(...): Computes the singular value decompositions of one or more matrices.\n",
    "\n",
    "tensor_diag(...): Returns a diagonal tensor with a given diagonal values.\n",
    "\n",
    "tensor_diag_part(...): Returns the diagonal part of the tensor.\n",
    "\n",
    "tensordot(...): Tensor contraction of a and b along specified axes and outer product.\n",
    "\n",
    "trace(...): Compute the trace of a tensor x.\n",
    "\n",
    "triangular_solve(...): Solve systems of linear equations with upper or lower triangular matrices.\n",
    "\n",
    "tridiagonal_matmul(...): Multiplies tridiagonal matrix by matrix.\n",
    "\n",
    "tridiagonal_solve(...): Solves tridiagonal systems of equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.losses`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an alias for `tf.keras.losses`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.math`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some main functions are:\n",
    "\n",
    "abs(...): Computes the absolute value of a tensor.\n",
    "\n",
    "accumulate_n(...): Returns the element-wise sum of a list of tensors.\n",
    "\n",
    "acos(...): Computes acos of x element-wise.\n",
    "\n",
    "acosh(...): Computes inverse hyperbolic cosine of x element-wise.\n",
    "\n",
    "add(...): Returns x + y element-wise.\n",
    "\n",
    "add_n(...): Adds all input tensors element-wise.\n",
    "\n",
    "angle(...): Returns the element-wise argument of a complex (or real) tensor.\n",
    "\n",
    "approx_max_k(...): Returns max k values and their indices of the input operand in an approximate manner.\n",
    "\n",
    "approx_min_k(...): Returns min k values and their indices of the input operand in an approximate manner.\n",
    "\n",
    "argmax(...): Returns the index with the largest value across axes of a tensor.\n",
    "\n",
    "argmin(...): Returns the index with the smallest value across axes of a tensor.\n",
    "\n",
    "asin(...): Computes the trignometric inverse sine of x element-wise.\n",
    "\n",
    "asinh(...): Computes inverse hyperbolic sine of x element-wise.\n",
    "\n",
    "atan(...): Computes the trignometric inverse tangent of x element-wise.\n",
    "\n",
    "atan2(...): Computes arctangent of y/x element-wise, respecting signs of the arguments.\n",
    "\n",
    "atanh(...): Computes inverse hyperbolic tangent of x element-wise.\n",
    "\n",
    "bessel_i0(...): Computes the Bessel i0 function of x element-wise.\n",
    "\n",
    "bessel_i0e(...): Computes the Bessel i0e function of x element-wise.\n",
    "\n",
    "bessel_i1(...): Computes the Bessel i1 function of x element-wise.\n",
    "\n",
    "bessel_i1e(...): Computes the Bessel i1e function of x element-wise.\n",
    "\n",
    "betainc(...): Compute the regularized incomplete beta integral .\n",
    "\n",
    "bincount(...): Counts the number of occurrences of each value in an integer array.\n",
    "\n",
    "ceil(...): Return the ceiling of the input, element-wise.\n",
    "\n",
    "confusion_matrix(...): Computes the confusion matrix from predictions and labels.\n",
    "\n",
    "conj(...): Returns the complex conjugate of a complex number.\n",
    "\n",
    "cos(...): Computes cos of x element-wise.\n",
    "\n",
    "cosh(...): Computes hyperbolic cosine of x element-wise.\n",
    "\n",
    "count_nonzero(...): Computes number of nonzero elements across dimensions of a tensor.\n",
    "\n",
    "cumprod(...): Compute the cumulative product of the tensor x along axis.\n",
    "\n",
    "cumsum(...): Compute the cumulative sum of the tensor x along axis.\n",
    "\n",
    "cumulative_logsumexp(...): Compute the cumulative log-sum-exp of the tensor x along axis.\n",
    "\n",
    "digamma(...): Computes Psi, the derivative of Lgamma (the log of the absolute value of\n",
    "\n",
    "divide(...): Computes Python style division of x by y.\n",
    "\n",
    "divide_no_nan(...): Computes a safe divide which returns 0 if y (denominator) is zero.\n",
    "\n",
    "equal(...): Returns the truth value of (x == y) element-wise.\n",
    "\n",
    "erf(...): Computes the Gauss error function of x element-wise. In statistics, for non-negative values of , the error function has the following interpretation: for a random variable  that is normally distributed with mean 0 and variance ,  is the probability that  falls in the range .\n",
    "\n",
    "erfc(...): Computes the complementary error function of x element-wise.\n",
    "\n",
    "erfcinv(...): Computes the inverse of complementary error function.\n",
    "\n",
    "erfinv(...): Compute inverse error function.\n",
    "\n",
    "exp(...): Computes exponential of x element-wise. .\n",
    "\n",
    "expm1(...): Computes exp(x) - 1 element-wise.\n",
    "\n",
    "floor(...): Returns element-wise largest integer not greater than x.\n",
    "\n",
    "floordiv(...): Divides x / y elementwise, rounding toward the most negative integer.\n",
    "\n",
    "floormod(...): Returns element-wise remainder of division. When x < 0 xor y < 0 is\n",
    "\n",
    "greater(...): Returns the truth value of (x > y) element-wise.\n",
    "\n",
    "greater_equal(...): Returns the truth value of (x >= y) element-wise.\n",
    "\n",
    "igamma(...): Compute the lower regularized incomplete Gamma function P(a, x).\n",
    "\n",
    "igammac(...): Compute the upper regularized incomplete Gamma function Q(a, x).\n",
    "\n",
    "imag(...): Returns the imaginary part of a complex (or real) tensor.\n",
    "\n",
    "in_top_k(...): Says whether the targets are in the top K predictions.\n",
    "\n",
    "invert_permutation(...): Computes the inverse permutation of a tensor.\n",
    "\n",
    "is_finite(...): Returns which elements of x are finite.\n",
    "\n",
    "is_inf(...): Returns which elements of x are Inf.\n",
    "\n",
    "is_nan(...): Returns which elements of x are NaN.\n",
    "\n",
    "is_non_decreasing(...): Returns True if x is non-decreasing.\n",
    "\n",
    "is_strictly_increasing(...): Returns True if x is strictly increasing.\n",
    "\n",
    "l2_normalize(...): Normalizes along dimension axis using an L2 norm. (deprecated arguments)\n",
    "\n",
    "lbeta(...): Computes , reducing along the last dimension.\n",
    "\n",
    "less(...): Returns the truth value of (x < y) element-wise.\n",
    "\n",
    "less_equal(...): Returns the truth value of (x <= y) element-wise.\n",
    "\n",
    "lgamma(...): Computes the log of the absolute value of Gamma(x) element-wise.\n",
    "\n",
    "log(...): Computes natural logarithm of x element-wise.\n",
    "\n",
    "log1p(...): Computes natural logarithm of (1 + x) element-wise.\n",
    "\n",
    "log_sigmoid(...): Computes log sigmoid of x element-wise.\n",
    "\n",
    "log_softmax(...): Computes log softmax activations.\n",
    "\n",
    "logical_and(...): Returns the truth value of x AND y element-wise.\n",
    "\n",
    "logical_not(...): Returns the truth value of NOT x element-wise.\n",
    "\n",
    "logical_or(...): Returns the truth value of x OR y element-wise.\n",
    "\n",
    "logical_xor(...): Logical XOR function.\n",
    "\n",
    "maximum(...): Returns the max of x and y (i.e. x > y ? x : y) element-wise.\n",
    "\n",
    "minimum(...): Returns the min of x and y (i.e. x < y ? x : y) element-wise.\n",
    "\n",
    "mod(...): Returns element-wise remainder of division. When x < 0 xor y < 0 is\n",
    "\n",
    "multiply(...): Returns an element-wise x * y.\n",
    "\n",
    "multiply_no_nan(...): Computes the product of x and y and returns 0 if the y is zero, even if x is NaN or infinite.\n",
    "\n",
    "ndtri(...): Compute quantile of Standard Normal.\n",
    "\n",
    "negative(...): Computes numerical negative value element-wise.\n",
    "\n",
    "nextafter(...): Returns the next representable value of x1 in the direction of x2, element-wise.\n",
    "\n",
    "not_equal(...): Returns the truth value of (x != y) element-wise.\n",
    "\n",
    "polygamma(...): Compute the polygamma function .\n",
    "\n",
    "polyval(...): Computes the elementwise value of a polynomial.\n",
    "\n",
    "pow(...): Computes the power of one value to another.\n",
    "\n",
    "real(...): Returns the real part of a complex (or real) tensor.\n",
    "\n",
    "reciprocal(...): Computes the reciprocal of x element-wise.\n",
    "\n",
    "reciprocal_no_nan(...): Performs a safe reciprocal operation, element wise.\n",
    "\n",
    "reduce_all(...): Computes tf.math.logical_and of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_any(...): Computes tf.math.logical_or of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_euclidean_norm(...): Computes the Euclidean norm of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_logsumexp(...): Computes log(sum(exp(elements across dimensions of a tensor))).\n",
    "\n",
    "reduce_max(...): Computes tf.math.maximum of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_mean(...): Computes the mean of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_min(...): Computes the tf.math.minimum of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_prod(...): Computes tf.math.multiply of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_std(...): Computes the standard deviation of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_sum(...): Computes the sum of elements across dimensions of a tensor.\n",
    "\n",
    "reduce_variance(...): Computes the variance of elements across dimensions of a tensor.\n",
    "\n",
    "rint(...): Returns element-wise integer closest to x.\n",
    "\n",
    "round(...): Rounds the values of a tensor to the nearest integer, element-wise.\n",
    "\n",
    "rsqrt(...): Computes reciprocal of square root of x element-wise.\n",
    "\n",
    "scalar_mul(...): Multiplies a scalar times a Tensor or IndexedSlices object.\n",
    "\n",
    "segment_max(...): Computes the maximum along segments of a tensor.\n",
    "\n",
    "segment_mean(...): Computes the mean along segments of a tensor.\n",
    "\n",
    "segment_min(...): Computes the minimum along segments of a tensor.\n",
    "\n",
    "segment_prod(...): Computes the product along segments of a tensor.\n",
    "\n",
    "segment_sum(...): Computes the sum along segments of a tensor.\n",
    "\n",
    "sigmoid(...): Computes sigmoid of x element-wise.\n",
    "\n",
    "sign(...): Returns an element-wise indication of the sign of a number.\n",
    "\n",
    "sin(...): Computes sine of x element-wise.\n",
    "\n",
    "sinh(...): Computes hyperbolic sine of x element-wise.\n",
    "\n",
    "sobol_sample(...): Generates points from the Sobol sequence.\n",
    "\n",
    "softmax(...): Computes softmax activations.\n",
    "\n",
    "softplus(...): Computes elementwise softplus: softplus(x) = log(exp(x) + 1).\n",
    "\n",
    "softsign(...): Computes softsign: features / (abs(features) + 1).\n",
    "\n",
    "sqrt(...): Computes element-wise square root of the input tensor.\n",
    "\n",
    "square(...): Computes square of x element-wise.\n",
    "\n",
    "squared_difference(...): Returns conj(x - y)(x - y) element-wise.\n",
    "\n",
    "subtract(...): Returns x - y element-wise.\n",
    "\n",
    "tan(...): Computes tan of x element-wise.\n",
    "\n",
    "tanh(...): Computes hyperbolic tangent of x element-wise.\n",
    "\n",
    "top_k(...): Finds values and indices of the k largest entries for the last dimension.\n",
    "\n",
    "truediv(...): Divides x / y elementwise (using Python 3 division operator semantics).\n",
    "\n",
    "unsorted_segment_max(...): Computes the maximum along segments of a tensor.\n",
    "\n",
    "unsorted_segment_mean(...): Computes the mean along segments of a tensor.\n",
    "\n",
    "unsorted_segment_min(...): Computes the minimum along segments of a tensor.\n",
    "\n",
    "unsorted_segment_prod(...): Computes the product along segments of a tensor.\n",
    "\n",
    "unsorted_segment_sqrt_n(...): Computes the sum along segments of a tensor divided by the sqrt(N).\n",
    "\n",
    "unsorted_segment_sum(...): Computes the sum along segments of a tensor.\n",
    "\n",
    "xdivy(...): Returns 0 if x == 0, and x / y otherwise, elementwise.\n",
    "\n",
    "xlog1py(...): Compute x * log1p(y).\n",
    "\n",
    "xlogy(...): Returns 0 if x == 0, and x * log(y) otherwise, elementwise.\n",
    "\n",
    "zero_fraction(...): Returns the fraction of zeros in value.\n",
    "\n",
    "zeta(...): Compute the Hurwitz zeta function ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.strings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions are:\n",
    "\n",
    "as_string(...): Converts each entry in the given tensor to strings.\n",
    "\n",
    "bytes_split(...): Split string elements of input into bytes.\n",
    "\n",
    "format(...): Formats a string template using a list of tensors.\n",
    "\n",
    "join(...): Perform element-wise concatenation of a list of string tensors.\n",
    "\n",
    "length(...): String lengths of input.\n",
    "\n",
    "lower(...): Converts all uppercase characters into their respective lowercase replacements.\n",
    "\n",
    "ngrams(...): Create a tensor of n-grams based on data.\n",
    "\n",
    "reduce_join(...): Joins all strings into a single string, or joins along an axis.\n",
    "\n",
    "regex_full_match(...): Check if the input matches the regex pattern.\n",
    "\n",
    "regex_replace(...): Replace elements of input matching regex pattern with rewrite.\n",
    "\n",
    "split(...): Split elements of input based on sep into a RaggedTensor.\n",
    "\n",
    "strip(...): Strip leading and trailing whitespaces from the Tensor.\n",
    "\n",
    "substr(...): Return substrings from Tensor of strings.\n",
    "\n",
    "to_hash_bucket(...): Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
    "\n",
    "to_hash_bucket_fast(...): Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
    "\n",
    "to_hash_bucket_strong(...): Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
    "\n",
    "to_number(...): Converts each string in the input Tensor to the specified numeric type.\n",
    "\n",
    "unicode_decode(...): Decodes each string in input into a sequence of Unicode code points.\n",
    "\n",
    "unicode_decode_with_offsets(...): Decodes each string into a sequence of code points with start offsets.\n",
    "\n",
    "unicode_encode(...): Encodes each sequence of Unicode code points in input into a string.\n",
    "\n",
    "unicode_script(...): Determine the script codes of a given tensor of Unicode integer code points.\n",
    "\n",
    "unicode_split(...): Splits each string in input into a sequence of Unicode code points.\n",
    "\n",
    "unicode_split_with_offsets(...): Splits each string into a sequence of code points with start offsets.\n",
    "\n",
    "unicode_transcode(...): Transcode the input text from a source encoding to a destination encoding.\n",
    "\n",
    "unsorted_segment_join(...): Joins the elements of inputs based on segment_ids.\n",
    "\n",
    "upper(...): Converts all lowercase characters into their respective uppercase replacements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2efee1efa502125d01e6b4768ba06d9453d29f3642bfd14ad5d4a769de82e88c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
