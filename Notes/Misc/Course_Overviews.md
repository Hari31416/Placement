- [1. Course Overview](#1-course-overview)
  - [1.1. Udemy Courses](#11-udemy-courses)
    - [1.1.1. Jose Portilla](#111-jose-portilla)
      - [1.1.1.1. 2022 Python for Machine Learning \& Data Science Masterclass](#1111-2022-python-for-machine-learning--data-science-masterclass)
      - [1.1.1.2. 2022 Complete Python Bootcamp From Zero to Hero in Python](#1112-2022-complete-python-bootcamp-from-zero-to-hero-in-python)
  - [1.2. Coursera Courses](#12-coursera-courses)
    - [1.2.1. Machine Learning Specialization](#121-machine-learning-specialization)
      - [1.2.1.1. **Course 1** **Supervised Machine Learning: Regression and Classification**](#1211-course-1-supervised-machine-learning-regression-and-classification)
      - [1.2.1.2. **Course 2** **Advanced Learning Algorithms**](#1212-course-2-advanced-learning-algorithms)
      - [1.2.1.3. **Course 3** **Unsupervised Learning, Recommenders, Reinforcement Learning**](#1213-course-3-unsupervised-learning-recommenders-reinforcement-learning)
    - [1.2.2. Deep Learning Specialization](#122-deep-learning-specialization)
      - [1.2.2.1. **Course 1** **Neural Networks and Deep Learning**](#1221-course-1-neural-networks-and-deep-learning)
      - [1.2.2.2. **Course 2** **Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization**](#1222-course-2-improving-deep-neural-networks-hyperparameter-tuning-regularization-and-optimization)
      - [1.2.2.3. **Course 3** **Structuring Machine Learning Projects**](#1223-course-3-structuring-machine-learning-projects)
      - [1.2.2.4. **Course 4** **Convolutional Neural Networks**](#1224-course-4-convolutional-neural-networks)
      - [1.2.2.5. **Course 5** **Sequence Models**](#1225-course-5-sequence-models)

# 1. Course Overview

Here, I'll provide a brief overview of the online courses I've taken. Basically, I'll give an overview of the syllabus and learning goal (if possible).

## 1.1. Udemy Courses

### 1.1.1. Jose Portilla

#### 1.1.1.1. 2022 Python for Machine Learning & Data Science Masterclass

**What Will You Learn?**

- You will learn how to use data science and machine learning with Python.
- You will create data pipeline workflows to analyze, visualize, and gain insights from data.
- You will build a portfolio of data science projects with real world data.
- You will be able to analyze your own data sets and gain insights through data science.
- Master critical data science skills.
- Understand Machine Learning from top to bottom.
- Replicate real-world situations and data reports.
- Learn NumPy for numerical processing with Python.
- Conduct feature engineering on real world case studies.
- Learn Pandas for data manipulation with Python.
- Create supervised machine learning algorithms to predict classes.
- Learn Matplotlib to create fully customized data visualizations with Python.
- Create regression machine learning algorithms for predicting continuous values.
- Learn Seaborn to create beautiful statistical plots with Python.
- Construct a modern portfolio of data science and machine learning resume projects.
- Learn how to use Scikit-learn to apply powerful machine learning algorithms.
- Get set-up quickly with the Anaconda data science stack environment.
- Learn best practices for real-world data sets.
- Understand the full product workflow for the machine learning lifecycle.
- Explore how to deploy your machine learning models as interactive APIs.

**Syllabus**

- Python Crash Course
- NumPy
  - Arrays
  - Indexing
  - Operations
- Pandas
  - Series
  - DataFrame
    - Working With Rows
    - Working With Columns
  - Conditional Filtering
  - Statistical Methods
  - Missing Data
  - Group By
    - MultiIndex
  - Combining DataFrame
    - Concatenation
    - Inner Merge
    - Left and Right Merge
    - Outer Merge
  - Text and Time Methods
  - IO
    - CSV
    - HTML
    - Excel
    - SQL
  - Pivot Tables
- Matplotlib
  - Basics
  - Functional and OOP Approach
  - Figures and Axes
  - Subplots
  - Legends
  - Colors and Style
- Seaborn
  - Simple Plots
  - Understanding Categorical Plots
    - Statistics within Categories
    - Distributions within Categories
  - Seaborn Grid
  - Matrix
- ML Concepts
  - Why ML?
  - Types
    - Supervised
    - Unsupervised
- Linear Regression
  - Intution and History
  - Cost Function
  - GD
  - Simple LR With Python
  - LR in Scikit-Learn
  - Residual Plots
  - Coefficient Interpretation
  - Polynomial Regression
    - Motivation
    - Thoery
    - Creating Features
  - Bias variance Trade Off
  - Model Deplyoment
  - Regularization
    - Ridge
    - Lasso
    - ElasticNet
  - Feature Scaling
- Feature Engineering
  - Outliers
  - Missing Data
    - Dropping
    - Statistical Values
    - Unique Value
  - Categorical Data
    - One-Hot Encoding
    - Label Encoding
- Cross Validation
  - Using scikit learn
- Grid Search
- Logistic Regression
  - Thoery and Intution
  - From Linear Regression to Logistic
  - Metrics
    - Accuracy
    - Precision
    - Recall
    - F1-Score
    - Confusion Matrix
    - ROC Curves
- KNN
  - Theory and Intution
  - Choosing K
    - Knee Method
- SVM
  - Theory and Intution
    - Hyperplane
    - Margin
    - Kernel Trick
    - SVM as Classifier
    - SVM as Regressor
- Decision Tree
  - History
  - Terminology
    - Root
    - Leaf
    - Branch
  - Constructing Tree
    - Gini Impurity
- Random Forest
  - History and Motivation
  - Key Hyperparameters
  - Bootsrapping and OOB Error
- Boosting Methods
  - Intro
  - Theory and Intution
  - Gradient Boosting
- Niave Bayes
  - Intro to NLP
  - Naive Bayes
    - Bayes Theorem
    - The Algorithms
  - Feature from Text
    - Count Vectorizer
    - Tf-idf
    - Using scikit-learn
  - NLP Model
  
- K-Means Clustering
  - Theory
  - Application in Color Quantization
- Hierarchical Clustering
  - Theory and Intution
  - Visualizing
- DBSCAN
  - Theory and Intution
  - DBSCAN vs K-Means
  - Hyperparameter Theory
    - Tuning HP
  - Outlier Detection using DBSCAN
- PCA
  - Thoery and Intution
  - Manual Implemention
  - Using scikit-learn
- Model Deployment
  - Considerations
  - Model Persistence
  - Deploy Model as an API

#### 1.1.1.2. 2022 Complete Python Bootcamp From Zero to Hero in Python

**What Will You Learn?**

- You will learn how to leverage the power of Python to solve tasks.
- You will build games and programs that use Python libraries.
- You will be able to use Python for your own work problems or personal projects.
- You will create a portfolio of Python based projects you can share.
- Learn to use Python professionally, learning both Python 2 and Python 3!
- Create games with Python, like Tic Tac Toe and Blackjack!
- Learn advanced Python features, like the collections module and how to work with timestamps!
- Learn to use Object Oriented Programming with classes!
- Understand complex topics, like decorators.
- Understand how to use both the Jupyter Notebook and create .py files
- Get an understanding of how to create GUIs in the Jupyter Notebook system!
- Build a complete understanding of Python from the ground up!

**Syllabus**

- Data Structure
  - Numbers
    - `int`
    - `float`
  - String
    - Slicing
    - Indexing
    - Print and Formatting
  - Lists
  - Dictionaries
  - Tuples
  - Booleans
  - Sets
  - IO
- Comparison Operators
- Statements
  - `if`, `elif`, `else`
  - For Loops
  - While Loops
  - List Comprehension
- Methods and Functions
  - `def` keyword
  - Tuple unpacking
  - Interaction between python functions
  - `*args` and `**kwargs`
  - Lambda Expression
  - `map` and `filter` functions
  - Scopes
- OOP
  - Intro
  - `class` keyword
  - Attributes
  - Methods
  - Speccial (magic/dunder) Methods
- Modules and Packeges
  - `__name__` and `"__main__"`
- Error and Exception handling
  - Pylint
  - Unittest
- Python Decorators and Generators
- Advanced Python Modules
  - `collections`
  - `os`
  - `datetime`
  - `math`, `random`
  - Regular Expressions
  - Timing Code
  - Zipping and Unzipping
- Web Scrapping with Python
  - Using `bs4` and `requests`
    - Interacting with Webpages
    - Downloading Images
- More Advanced Libraries
  - Pillow for Images
  - Working with CSV and PDFs
  - Sending emails
- Simple GUI
  - Interact Functionality
  - Widget Basics
  - Styling and Layouts

---
---

## 1.2. Coursera Courses

### 1.2.1. [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)

>The Machine Learning Specialization is a foundational online program created in collaboration between DeepLearning.AI and Stanford Online. This beginner-friendly program will teach you the fundamentals of machine learning and how to use these techniques to build real-world AI applications.
>
>This Specialization is taught by Andrew Ng, an AI visionary who has led critical research at Stanford University and groundbreaking work at Google Brain, Baidu, and Landing.AI to advance the AI field.
>This 3-course Specialization is an updated version of Andrew’s pioneering Machine Learning course, rated 4.9 out of 5 and taken by over 4.8 million learners since it launched in 2012.
>
>It provides a broad introduction to modern machine learning, including supervised learning (multiple linear regression, logistic regression, neural networks, and decision trees), unsupervised learning (clustering, dimensionality reduction, recommender systems), and some of the best practices used in Silicon Valley for artificial intelligence and machine learning innovation (evaluating and tuning models, taking a data-centric approach to improving performance, and more.)
>
>By the end of this Specialization, you will have mastered key concepts and gained the practical know-how to quickly and powerfully apply machine learning to challenging real-world problems. If you’re looking to break into AI or build a career in machine learning, the new Machine Learning Specialization is the best place to start.

**WHAT YOU WILL LEARN**

- Build ML models with NumPy & scikit-learn, build & train supervised models for prediction & binary classification tasks (linear, logistic regression)
- Build & train a neural network with TensorFlow to perform multi-class classification, & build & use decision trees & tree ensemble methods
- Apply best practices for ML development & use unsupervised learning techniques for unsupervised learning including clustering & anomaly detection
- Build recommender systems with a collaborative filtering approach & a content-based deep learning method & build a deep reinforcement learning model

#### 1.2.1.1. **Course 1** [**Supervised Machine Learning: Regression and Classification**](https://www.coursera.org/learn/machine-learning?specialization=machine-learning-introduction)

**Goals:**

- Build machine learning models in Python using popular machine learning libraries NumPy and scikit-learn.
- Build and train supervised machine learning models for prediction and binary classification tasks, including linear regression and logistic regression

**Syllabus:**

- Introduction to Machine Learning
  - Linear Regression with One Variable
  - Cost Function
  - Gradient Descent
  - Learning Rate

- Regression with multiple input variables
  - Multiple Features
  - Vectorization
  - Feature Scaling
  - Feature Engineering
  - Polynomial Regression

- Classification
  - Logistic Regression
  - Decision Boundary
  - Cost Function for Logistic Regression
  - Overfitting
  - Regularization
  
#### 1.2.1.2. **Course 2** [**Advanced Learning Algorithms**](https://www.coursera.org/learn/advanced-learning-algorithms?specialization=machine-learning-introduction)

**Goals:**

- Build and train a neural network with TensorFlow to perform multi-class classification
- Apply best practices for machine learning development so that your models generalize to data and tasks in the real world
- Build and use decision trees and tree ensemble methods, including random forests and boosted trees

**Syllabus**

- Neural Networks
  - Neurons and the brain
  - Neural network layer
  - Recognizing Images
  - Inference
  - Intro to Tensorflow
  - General implementation of forward propagation
  - AGI, Matrix Multiplication (Optional)

- Neural network training
  - TensorFlow implementation
  - Activation Functions and Their Need
    - Sigmoid
    - Softmax
    - ReLu
    - tanh
  - Multiclass
  - Improved Implementation of softmax
  - Advanced Optimization
    - Momentum
    - RMSProp
    - Adam
  - Additional Layers
    - CNN
    - GRU
    - LSTM

- Advice for applying machine learning
  - Evaluating a model
  - train/dev/test sets
  - Bias and Variance
  - Regularization
  - Baseline model
  - Learning curves
  - Bias/Variance with NN
  - Iterative loop of ML development
  - Error Analysis
  - Transfer Learning
  
- Decision Trees
  - The Model
  - Learning Decision Trees
  - Measuring Purity
    - Entropy
    - gini index
  - Information gain and creating a tree
  - One hot encoding
  - Continuous features
  - Regression trees (optional)
  - Multiple Decision Trees
  - Sampling with replacement
  - Random Forest and XGBoost

#### 1.2.1.3. **Course 3** [**Unsupervised Learning, Recommenders, Reinforcement Learning**](https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning?specialization=machine-learning-introduction)

**Goals:**

- Use unsupervised learning techniques for unsupervised learning: including clustering and anomaly detection.
- Build recommender systems with a collaborative filtering approach and a content-based deep learning method.
- Build a deep reinforcement learning model.

**Syllabus:**

- Unsupervised learning
  - Clustering
    - K-means
      - Initialization
      - Number of Clusters
    - Normal Distribution
    - Anamoly Detection Algorithm
    - Anomaly detection vs. supervised learning

- Recommender systems
  - Collaborative filtering
    - Mean normalization
    - Tensorflow implementation
  - Finding Related Items
  - Collaborative filtering vs Content-based filtering
  - Deep learning for content-based filtering

- Reinforcement learning
  - Introduction using Mars rover example
  - Concepts
    - Return
    - Policy
    - State-action value function
    - Bellman equation
    - continuous state space
  - Learning the state-value function
  - NN for state-value function
  - $\epsilon$ greedy policy
  - Mini-batch and soft updates (optional)
  
---

### 1.2.2. [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning)

>The Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology.
>
>In this Specialization, you will build and train neural network architectures such as Convolutional Neural Networks, Recurrent Neural Networks, LSTMs, Transformers, and learn how to make them better with strategies such as Dropout, BatchNorm, Xavier/He initialization, and more. Get ready to master theoretical concepts and their industry applications using Python and TensorFlow and tackle real-world cases such as speech recognition, music synthesis, chatbots, machine translation, natural language processing, and more.
>
>AI is transforming many industries. The Deep Learning Specialization provides a pathway for you to take the definitive step in the world of AI by helping you gain the knowledge and skills to level up your career. Along the way, you will also get career advice from deep learning experts from industry and academia.

**WHAT YOU WILL LEARN**

- Build and train deep neural networks, implement vectorized neural networks, identify architecture parameters, and apply DL to your applications

- Use best practices to train and develop test sets and analyze bias/variance for building DL applications, use standard NN techniques, apply optimization algorithms, and implement a neural network in TensorFlow

- Use strategies for reducing errors in ML systems, understand complex ML settings, and apply end-to-end, transfer, and multi-task learning

- Build a Convolutional Neural Network, apply it to visual detection and recognition tasks, use neural style transfer to generate art, and apply these algorithms to image, video, and other 2D/3D data

- Build and train Recurrent Neural Networks and its variants (GRUs, LSTMs), apply RNNs to character-level language modeling, work with NLP and Word Embeddings, and use HuggingFace tokenizers and transformers to perform Named Entity Recognition and Question Answering

#### 1.2.2.1. **Course 1** [**Neural Networks and Deep Learning**](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning)

**Goals:**

By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.

**Syllabus:**

- Introduction to Deep Learning
  - Introduction
  - Why DL is taking off?
  
- Neural Networks Basics
  - Logistics Regression
  - Cost Function
  - Gradient Descent
  - Compuatation Graph
  - Vectorization and Vectorized Logistic Regression
  
- Shallow Neural Networks
  - NN Overview and representation
  - Vectorized NN
  - Activation Function and Their Need
  - Derivatives of Activation Functions and Gradient Descent
  - Random Initialization
  - Backpropagation Intution (Optional)
  
- Deep Neural Networks
  - Deep L-Layer NN
  - Building Blocks of NN
  - Forward and Backward Propagation
  - Parameters vs Hyperparameters
  - Analogy with Brain

#### 1.2.2.2. **Course 2** [**Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization**](https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning)

**Goals:**

By the end, you will learn the best practices to train and develop test sets and analyze bias/variance for building deep learning applications; be able to use standard neural network techniques such as initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking; implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence; and implement a neural network in TensorFlow.

**Syllabus**

- Practical Aspects of Deep Learning
  - Train/dev/Test sets
  - Bias/Variance
  - Regularization
    - How It reduces overfitting
  - Regularization Techniques
    - Dropuout and why it works
    - Normalization
  - Vanishing and Exploding Gradients
  - Weight Initization
  - Gradient Checking
  
- Optimization Algorithms
  - Mini Batch GD
  - Bias Correction in Exponentially Weighted Averages
  - Optimization Algorithms
    - GD with Momentum
    - RMSprop
    - Adam
  - Learning Rate Decay

- Hyperparameter Tuning, Batch Normalization and Programming Frameworks
  - Tuning Process
  - Normalizing Activations in a Network
  - Batch Norm
    - Why It Works?
    - At Test Time
  - Softmax Regression
  - DL Frameworks
    - TensorFlow
    - Keras

#### 1.2.2.3. **Course 3** [**Structuring Machine Learning Projects**](https://www.coursera.org/learn/machine-learning-projects?specialization=deep-learning)

**Goals:**

By the end, you will be able to diagnose errors in a machine learning system; prioritize strategies for reducing errors; understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance; and apply end-to-end learning, transfer learning, and multi-task learning.

**Syllabus**

- Introduction to ML Strategy
  - Orthogonalization
  - Single Number Evaluation Metric
  - Satisficing and Optimizing Metric
  - Train/Dev/Test Distributions
    - Size of the Dev and Test Sets
    - When to Change Dev/Test Sets and Metrics
    - Mismatched Training and Dev/Test Sets
  - Human Level Performance
    - Surpassing Human Level Performance
    - Improving Your Model Performance
  - Avoidable Bias

- Introduction to ML Strategy II
  - Error Analysis
    - Cleaning Up Incorrectly Labeled Data
  - Build your First System Quickly, then Iterate
  - Training and Testing on Different Distributions
    - Bias and Variance with Mismatched Data Distributions
    - Addressing Data Mismatch
  - End-to-End Deep Learning
    - Whether Use It?
  - Transfer Learning
  - Multi-task Learning

#### 1.2.2.4. **Course 4** [**Convolutional Neural Networks**](https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning)

**Goals:**

By the end, you will be able to build a convolutional neural network, including recent variations such as residual networks; apply convolutional networks to visual detection and recognition tasks; and use neural style transfer to generate art and apply these algorithms to a variety of image, video, and other 2D or 3D data.

**Syllabus:**

- Foundations of Convolutional Neural Networks
  - Computer Vision
  - Edge Detection
  - Padding
  - Stride
  - Convolution over Volume
  - One Layer of a Convolutional Network
    - Example of Simple Convolutional Network
  - Pooling Layers
  - CNN Example
  - Why CNN

- Deep Convolutional Models: Case Studies
  - Classic Networks
    - ResNets
      - Why It Works
    - Inception
      - Its Motivation
    - MobileNet
    - EfficientNet
    - Transfer Learning
    - Data Augmentation
    - Networks in Networks and 1x1 Convolutions

- Object Detection
  - Object Localization
  - Landmark Detection
  - Object Detection
  - Convolutional Implementation of Sliding Windows
  - Bounding Box Predictions
  - Intersection Over Union
  - Non-max Suppression
  - Anchor Boxes
  - YOLO Algorithm
  - Semantic Segmentation with U-Net
    - U-Net Architecture
  - Transpose Convolution

- Special Applications: Face recognition & Neural Style Transfer
  - Face Recognition
    - One Shot Learning
    - Siamese Network
    - Triplet Loss
    - Face Verification and Binary Classification
  - Neural Style Transfer
    - What the CovNets learning?
    - Content and Style Cost Function
    - 1D and 3D Generalizations

#### 1.2.2.5. **Course 5** [**Sequence Models**](https://www.coursera.org/learn/nlp-sequence-models?specialization=deep-learning)

**Goals:**

By the end, you will be able to build and train Recurrent Neural Networks (RNNs) and commonly-used variants such as GRUs and LSTMs; apply RNNs to Character-level Language Modeling; gain experience with natural language processing and Word Embeddings; and use HuggingFace tokenizers and transformer models to solve different NLP tasks such as NER and Question Answering.

**Syllabus**

- Recurrent Neural Networks
  - Why Sequence Model
  - RNN
    - Back Propagation Through Time
    - Different Types
    - Vanishing Gradients with RNNs
  - Language Model and Sequence Generation
  - Sampling Novel Sequences
  - GRU
  - LSTM
  - DRRN
  - Deep RNN

- Natural Language Processing & Word Embeddings
  - Word Representation
    - Word Embedding
      - Properties
      - Embedding Matrix
      - Learning Word Embeddings
  - Word2Vec
  - Negative Sampling
  - GloVe Word Vectors
  - Sentiment Classification
  - Debiasing WE's

- Sequence Models & Attention Mechanism
  - Picking the Most Likely Sentence
    - Beam Search
      - Refinement
      - Error
    - Bleu Score
  - Attention Model
  - Speech Recognition
    - Trigger Word Detection

- Transformer Network
  - Self Attention
  - Multi-Head Attention
  - Transformer Network