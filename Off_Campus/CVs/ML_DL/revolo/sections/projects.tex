%-----------PROJECTS--------------------------
% Use resumeQuadHeading if four elements are feasible (ex: demo video link), else use resumeTrioHeading. Keep the bullet points simple and concise and try to cover wide variety of skills you have used to build these projects

\section{Projects}
\resumeHeadingListStart{}

% ReVision
\resumeTrioHeading{ReVision}{Python, Numpy, TensorFlow, Pytorch, CLI}{\href{https://github.com/Hari31416/ReVision}{\uline{Source Code}}}
\resumeItemListStart{}
\resumeItem{Created a personal project called \textbf{ReVision} to learn the concepts and implementation details of groundbreaking \textbf{computer vision papers}.}
\resumeItem{Utilized popular deep learning frameworks such as \textbf{Tensorflow} and \textbf{PyTorch} to implement the architectures of seminal papers like \textbf{LeNet}, \textbf{AlexNet}, \textbf{VGG}, \textbf{ResNet}, \textbf{Inception}, \textbf{EfficientNet}, etc.}
\resumeItemListEnd{}

% Natural Language Processing with Disaster Tweets
\resumeTrioHeading{NLP With Disaster Tweets}{Python, TensorFlow, NLP, Text Vectorization, LSTM, GRU, CNN}{\href{https://github.com/Hari31416/Portfolio/tree/main/ML/Disaster_Tweets}{\uline{Source Code}}}
\resumeItemListStart{}
\resumeItem{Developed NLP models to classify disaster and non-disaster tweets using \textbf{text vectorization}, various \textbf{word embeddings}, and deep learning models including \textbf{LSTM}, \textbf{GRU}, their \textbf{bidirectional} variants, and \textbf{1D CNNs}}
\resumeItem{Utilized the \textbf{Universal Sentence Encoder} to create embeddings on both the character and word levels, and implemented a \textbf{multivariate} model using the \textbf{functional API} of \textbf{TensorFlow}.}
\resumeItemListEnd{}

% IBM Data Analytics
% More techs: Web Scraping, Web API, dashboard, presentation, BI 
\resumeTrioHeading{IBM Data Analytics Capstone Project}{Python, pandas, Matplotlib, Web Scraping, API, Dashboard}{}
\resumeItemListStart{}
\resumeItem{Gathered and analyzed data from various sources, including \textbf{API} and \textbf{web scraping}. Conducted \textbf{exploratory data analysis} and \textbf{wrangling} to prepare the data for further analysis.}
\resumeItem{Built a \textbf{dynamic dashboard} to extract valuable insights from the collected data, and effectively \textbf{communicated} the findings to others through an \textbf{engaging presentation}.}
\resumeItemListEnd{}

% Tableau
\resumeTrioHeading{Tableau Dashboards}{Tableau, Web Scraping, Web API, BeautifulSoup}{\href{https://public.tableau.com/app/profile/hari31416/viz/Spotifyin2022/SummaryAndTaylorSupremacy}{\uline{Music}} \href{https://public.tableau.com/app/profile/hari31416/viz/Booksin2022/MyBooksin2022}{\uline{Books}}}
\resumeItemListStart{}
\resumeItem{Created an interactive \textbf{Tableau} \textbf{viz} showcasing my \textbf{Spotify} \textbf{streaming history} over several years, using \textbf{data blending} and \textbf{calculated fields} to present key insights.}
\resumeItem{Utilized \textbf{web scraping} techniques to extract my book reading history from \textbf{Goodreads} and created an interactive \textbf{Tableau} dashboard to analyze and visualize the data.}
\resumeItemListEnd{}

\resumeHeadingListEnd{}
