{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "<td style=\"border: none;\">\n",
    "<a target=\"blank\" href=\"https://colab.research.google.com/github/Hari31416/Portfolio/blob/main/ML\\Disaster_Tweets\\Preprocessing.ipynb?hl=en\"><img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\" width=\"28\" height=\"28\"/>Run on Google Colab</a></td>\n",
    "<td style=\"border: none;\">\n",
    "<a target=\"blank\" href=\"https://github.com/Hari31416/Portfolio/blob/main/ML\\Disaster_Tweets\\Preprocessing.ipynb\"><img src=\"https://cdn.icon-icons.com/icons2/2368/PNG/512/github_logo_icon_143772.png\" width=\"28\" height=\"28\"/>View on Github</a></td>\n",
    "<td style=\"border: none;\">\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Contents\">Contents<a href=\"#Contents\"></a></h1>\n",
    "        <ol>\n",
    "        <li><a class=\"\" href=\"#Imports\">Imports</a></li>\n",
    "<li><a class=\"\" href=\"#Getting-Data-Ready\">Getting Data Ready</a></li>\n",
    "<ol><li><a class=\"\" href=\"#Downloading-the-Data\">Downloading the Data</a></li>\n",
    "<li><a class=\"\" href=\"#Extracting-the-Data\">Extracting the Data</a></li>\n",
    "<li><a class=\"\" href=\"#Loading-the-Data\">Loading the Data</a></li>\n",
    "</ol><li><a class=\"\" href=\"#Preprocessing\">Preprocessing</a></li>\n",
    "<ol><li><a class=\"\" href=\"#Null-Values\">Null Values</a></li>\n",
    "<ol><li><a class=\"\" href=\"#location-Column\">location Column</a></li>\n",
    "<li><a class=\"\" href=\"#Keyword-Column\">Keyword Column</a></li>\n",
    "</ol><li><a class=\"\" href=\"#Cleaning-the-Text-Column\">Cleaning the Text Column</a></li>\n",
    "<ol><li><a class=\"\" href=\"#Saving-the-Cleaned-Data\">Saving the Cleaned Data</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.57034\n",
       "1    0.42966\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.value_counts(\"target\")/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of null values in the data. Let's handle them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `location` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"location\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Birmingham', 'Est. September 2012 - Bristol', 'AFRICA',\n",
       "       'Philadelphia, PA', 'London, UK', 'Pretoria', 'World Wide!!',\n",
       "       'Paranaque City', 'Live On Webcam', 'milky way',\n",
       "       'GREENSBORO,NORTH CAROLINA', 'England.',\n",
       "       'Sheffield Township, Ohio', 'India', 'Barbados', 'Anaheim',\n",
       "       'Abuja', 'USA', 'South Africa'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = train[\"location\"].unique()\n",
    "locations[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3341 unique values in the `location` column. Furthermore, the values of `location` are not very relavant to whether the tweet corresponds to diasaster or not. For now, we will not use this column for further analysis. Let's head to the `keyword` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Keyword` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"keyword\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = train[\"keyword\"].unique()\n",
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the column contain 221 unique values our first thought would be to drop this columns too. However, the keywords are highly relevant to the disaster. Therefore, we will keep this column. How to use this in model, we will see later. First, we need to fill the null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these keywords are related by the `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_text = train[train[\"keyword\"].notna()][[\"keyword\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casualty\n",
      "Casualty Team: Ice Cream Recall Sends Chill Through Food Industry http://t.co/6GsAmY6mts\n",
      "\n",
      "\n",
      "hellfire\n",
      "day 3 without my phone and due to my slow shite computers it is utter hellfire :'(\n",
      "Plez send help\n",
      "\n",
      "\n",
      "displaced\n",
      "Displaced Persons GN (2014 Image) #1-1ST NM http://t.co/yEJt18sbm0 http://t.co/RcqacN91bE\n",
      "\n",
      "\n",
      "bridge%20collapse\n",
      "Leicester_Merc : ICYMI - #Ashes 2015: Australia collapse at Trent Bridge - how Twitter reaÛ_ http://t.co/HqeWMREysO) http://t.co/y4y8fclJED\n",
      "\n",
      "\n",
      "emergency%20services\n",
      "Services are returning to normal #SouthLine after a medical emergency at Yennora and urgent track equipment repairs at Cabramatta earlier.\n",
      "\n",
      "\n",
      "ambulance\n",
      "@medic914 @AACE_org I am surprised we still cannot standardised the clinical practice across the 11 NHS ambulance trust.\n",
      "\n",
      "\n",
      "drought\n",
      "Thought it was a drought @_ASHJ? http://t.co/V4Br5gjMIY\n",
      "\n",
      "\n",
      "lightning\n",
      "@random_tourist it rained. Some guys tree hit by lightning and some jackholes drove onto flooded streets.\n",
      "\n",
      "\n",
      "mudslide\n",
      "You've 100% fucked up when Paul says your cake looks like a 'mudslide' and tastes like 'rubber'\n",
      "\n",
      "\n",
      "body%20bags\n",
      "Shoot shit up till we see body bags\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "indices= keyword_text.index\n",
    "for i in range(10):\n",
    "    index = random.choice(indices)\n",
    "    print(keyword_text.loc[index, \"keyword\"])\n",
    "    print(keyword_text.loc[index, \"text\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it seems that the `keyword` are taken from the `text`. We can use this fact to fill the null values in the `keyword` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "An IS group suicide bomber detonated an explosives-packed vest in a mosque inside a Saudi special forces headquarters killing 15 people.\n",
      "\n",
      "\n",
      "nan\n",
      "Love skiing\n",
      "\n",
      "\n",
      "nan\n",
      "Cooool :)\n",
      "\n",
      "\n",
      "nan\n",
      "London is cool ;)\n",
      "\n",
      "\n",
      "nan\n",
      "Do you like pasta?\n",
      "\n",
      "\n",
      "nan\n",
      "Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.\n",
      "\n",
      "\n",
      "nan\n",
      "Heat wave warning aa? Ayyo dei. Just when I plan to visit friends after a year.\n",
      "\n",
      "\n",
      "nan\n",
      "Heat wave warning aa? Ayyo dei. Just when I plan to visit friends after a year.\n",
      "\n",
      "\n",
      "nan\n",
      "The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d\n",
      "\n",
      "\n",
      "nan\n",
      "this is ridiculous....\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_text_null = train[train[\"keyword\"].isna()][[\"keyword\", \"text\"]]\n",
    "indices= keyword_text_null.index\n",
    "for i in range(10):\n",
    "    index = random.choice(indices)\n",
    "    print(keyword_text_null.loc[index, \"keyword\"])\n",
    "    print(keyword_text_null.loc[index, \"text\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill the null values, this is what we'll do:\n",
    "1. Make a list of all the keywords in the `keyword` column.\n",
    "2. Loop thorough the `text` for which the `keyword` is null.\n",
    "3. Search if there is a word in the text that is in the list of keywords.\n",
    "4. If yes, fill the `keyword` column with that word else fill with some other special word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before this, let's make some changes to the `keyword` column. We will be removing the final \"s\" from the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body%20bags\n",
      "burning%20buildings\n",
      "bush%20fires\n",
      "casualties\n",
      "deaths\n",
      "debris\n",
      "emergency%20services\n",
      "eyewitness\n",
      "fatalities\n",
      "first%20responders\n",
      "flames\n",
      "floods\n",
      "forest%20fires\n",
      "hazardous\n",
      "hostages\n",
      "injuries\n",
      "refugees\n",
      "rescuers\n",
      "screams\n",
      "sirens\n",
      "survivors\n",
      "weapons\n",
      "wild%20fires\n",
      "wounds\n"
     ]
    }
   ],
   "source": [
    "for word in keywords:\n",
    "    word = str(word)\n",
    "    if word.endswith(\"s\"):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_s(word):\n",
    "    if word is None:\n",
    "        return None\n",
    "    word = str(word).lower()\n",
    "    if word.endswith(\"s\"):\n",
    "        return word[:-1]\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "train[\"keyword\"] = train[\"keyword\"].apply(remove_s)\n",
    "test[\"keyword\"] = test[\"keyword\"].apply(remove_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 215, 215)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_keywords = train[\"keyword\"].unique()\n",
    "test_keywords = test[\"keyword\"].unique()\n",
    "all_keywords = np.concatenate([train_keywords, test_keywords])\n",
    "all_keywords = np.unique(all_keywords)\n",
    "len(train_keywords), len(test_keywords), len(all_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_keyword(row):\n",
    "    if row[\"keyword\"] == \"nan\":\n",
    "        for keyword in all_keywords:\n",
    "            if keyword in row[\"text\"].lower():\n",
    "                return keyword\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return row[\"keyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"keyword\"] = train[[\"keyword\", \"text\"]].apply(fill_keyword, axis=1)\n",
    "test[\"keyword\"] = test[[\"keyword\", \"text\"]].apply(fill_keyword, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(weapon                   78\n",
       " flood                    76\n",
       " death                    74\n",
       " body%20bag               74\n",
       " siren                    71\n",
       "                          ..\n",
       " neutral                  20\n",
       " epicentre                12\n",
       " threat                   11\n",
       " inundation               10\n",
       " radiation%20emergency     9\n",
       " Name: keyword, Length: 215, dtype: int64,\n",
       " hostage                  32\n",
       " siren                    31\n",
       " flood                    29\n",
       " death                    26\n",
       " body%20bag               26\n",
       "                          ..\n",
       " threat                    5\n",
       " fatalitie                 5\n",
       " radiation%20emergency     5\n",
       " inundation                4\n",
       " epicentre                 1\n",
       " Name: keyword, Length: 215, dtype: int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"keyword\"].value_counts(), test[\"keyword\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is working. Now we'll need to clean the `text` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the `Text` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we need to remove pucntuations, user tag, external links, and other special characters from the `text` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove the special characters as well as the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def clean(text):\n",
    "    #Lowering text\n",
    "    text = text.lower()\n",
    "\n",
    "    #Removing the @user\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "\n",
    "    #Removing the links\n",
    "    text = re.sub(r'http:\\S+', '', text)\n",
    "    text = re.sub(r'https:\\S+', '', text)\n",
    "\n",
    "    #Removing non ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    #Removing punctuation and special characters\n",
    "    chars = [\"!\", \"#\", \",\", \".\", \":\", \";\", \"?\", \"-\", \"~\", \")\", \"(\", \"=\", \">\", \"<\", \"/\"]\n",
    "    for char in chars:\n",
    "        if char in text:\n",
    "            text = text.replace(char, \"\")\n",
    "\n",
    "    stop = stopwords.words('english')\n",
    "    #To avoid getting empty strings\n",
    "    if len(text.split()) > 3:\n",
    "        text = [word for word in text.split() if word not in stop]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rockyfire update california hwy 20 closed directions due lake county fire cafire wildfires'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"#RockyFire @hari Update  => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\"\"\"\n",
    "clean(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boxes ready explode exploding kittens finally arrived gameofkittens explodingkittens_'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"These boxes are ready to explode! Exploding Kittens finally arrived! gameofkittens #explodingkittensÛ_ https://t.co/TFGrAyuDC5\"\n",
    "clean(text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working good enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(clean)\n",
    "test['text'] = test['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>6394</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>NAWF SIDE POKING OUT</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    keyword               location text  target\n",
       "4497  6394  hurricane  NAWF SIDE POKING OUT             1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"text\"].str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, keyword, location, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"text\"].str.len() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see thatone of text entries contain nothing at all. Let's remove this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[train[\"text\"].str.len() == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, keyword, location, text, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train[\"text\"].str.len() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we'll save the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train_clean.csv', index=False)\n",
    "test.to_csv('data/test_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2efee1efa502125d01e6b4768ba06d9453d29f3642bfd14ad5d4a769de82e88c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
